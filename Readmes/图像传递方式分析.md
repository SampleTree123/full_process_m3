# 图像传递方式详细分析

## 当前系统架构

### 1. 预处理服务 (preprocess.py)
**输入格式**: 文件路径 (string)
```python
# API 接收
image_path = data.get('image_path')

# 内部转换链
image_path (str) 
  → PIL.Image.open(image_path)           # 加载为 PIL.Image
  → np.array(pil_img)                    # 转为 numpy array
  → cv2处理 (裁剪、缩放)                  # OpenCV处理
  → Image.fromarray(cv2.cvtColor(...))   # 转回 PIL.Image
  → pair_img.save(output_path)           # 保存到磁盘
```
**输出格式**: 文件路径 (string)
```json
{
  "pair_image": "/path/to/group_0001/preprocess/panorama1_panorama2_interval0.jpg"
}
```

---

### 2. 超分服务 (osediff_api.py)
**输入格式**: 文件路径 (string)
```python
# API 接收
input_path = data.get('input_path')  # 或 input_paths 列表

# 内部转换链
input_path (str)
  → Image.open(input_path).convert('RGB')     # 加载为 PIL.Image
  → tensor_transforms(image)                   # PIL → Tensor
  → lq.unsqueeze(0).to(device)                # 添加batch维度并移到GPU
  → model(lq, prompt=...)                      # 模型推理 (tensor)
  → transforms.ToPILImage()(output[0].cpu())  # Tensor → PIL.Image
  → adain_color_fix(...)                       # PIL处理
  → output_pil.save(output_path)              # 保存到磁盘
```
**输出格式**: 文件路径 (string)
```json
{
  "success": true,
  "output_path": "/path/to/group_0001/osediff/image_sr.jpg"
}
```

---

### 3. 质量评估服务 (quality_api.py)
**输入格式**: 文件路径 (string)
```python
# API 接收
image_path = pair_data.get('pair_image')

# 内部转换链 (Qwen模型)
image_path (str)
  → messages = [{"type": "image", "image": f"file://{image_path}"}]
  → process_vision_info(messages)              # Qwen内部加载图像
  → processor(..., return_tensors="pt")        # 转为 PyTorch tensor
  → model.generate(**inputs)                   # 模型推理
  → (不保存图像，只返回评分)
```
**输出格式**: 文件路径 + 评分
```json
{
  "pair_image": "/path/to/image.jpg",
  "final_score": "0.85",
  "interval": 0
}
```

---

### 4. 插值生成服务 (preprocess.py)
**输入格式**: 文件路径 (string)
```python
# API 接收
left_path = split_result.get('left_image')
right_path = split_result.get('right_image')

# 内部转换链
[left_path, right_path] (str)
  → panorama_img = Image.open(path)           # 加载为 PIL.Image
  → panorama = np.array(panorama_img)         # 转为 numpy
  → cv2.resize(...) / cv2处理                  # OpenCV处理
  → Image.fromarray(cv2.cvtColor(crop, ...))  # 转回 PIL.Image
  → crop_rgb.save(interp_path)               # 保存到磁盘
```
**输出格式**: 文件路径 (string)
```json
{
  "path": "/path/to/group_0001/interpolated/interp_01.jpg",
  "weight_idx": 1
}
```

---

## 核心特征总结

### ✅ 优点
1. **服务解耦**: 各服务独立，通过文件系统隔离
2. **易于调试**: 可以检查每一步的中间结果
3. **容错性好**: 服务崩溃不影响已保存的数据
4. **可追溯**: 完整的文件历史记录

### ❌ 缺点（针对 tensor 传递需求）
1. **磁盘 I/O 开销大**: 每步都要读写磁盘
2. **格式转换开销**: PIL ↔ tensor ↔ numpy 多次转换
3. **内存效率低**: 重复加载相同图像
4. **无法直接传递 tensor**: 需要序列化/反序列化

---

## 如果要对接 Tensor 传递系统

### 方案 1: 添加 Tensor 接口（推荐）
为每个 API 服务添加 tensor 输入/输出接口：

```python
# 新增 tensor 接口示例
@app.route('/super_resolution_tensor', methods=['POST'])
def super_resolution_tensor_endpoint():
    """接收 base64 编码的 tensor"""
    data = request.get_json()
    
    # 接收 tensor (base64 编码)
    tensor_b64 = data.get('tensor')
    tensor = decode_tensor(tensor_b64)  # 解码
    
    # 处理 (跳过 Image.open 步骤)
    with torch.no_grad():
        output_tensor = model(tensor)
    
    # 返回 tensor (base64 编码)
    output_b64 = encode_tensor(output_tensor)
    return jsonify({"success": True, "tensor": output_b64})
```

### 方案 2: 共享内存（高性能）
使用 Redis/共享内存传递 tensor：

```python
import redis
import pickle

# 发送端
tensor_id = f"tensor_{uuid.uuid4()}"
redis_client.set(tensor_id, pickle.dumps(tensor))
api_call({'tensor_id': tensor_id})

# 接收端
tensor = pickle.loads(redis_client.get(tensor_id))
```

### 方案 3: gRPC 流式传递
用 gRPC 替代 Flask，支持高效二进制传递：

```protobuf
service ImageProcessor {
  rpc SuperResolution(TensorRequest) returns (TensorResponse);
}

message TensorRequest {
  bytes tensor_data = 1;
  repeated int32 shape = 2;
}
```

---

## 推荐改造步骤

### 阶段 1: 添加混合接口
保留原有的文件路径接口，新增 tensor 接口：
- `/super_resolution` (文件路径) ← 保留
- `/super_resolution_tensor` (tensor) ← 新增

### 阶段 2: 统一内部处理
创建统一的处理函数，支持两种输入：
```python
def process(input_data, input_type='path'):
    if input_type == 'path':
        tensor = load_image_to_tensor(input_data)
    else:  # 'tensor'
        tensor = input_data
    
    # 统一处理
    output = model(tensor)
    
    if input_type == 'path':
        return save_tensor_to_path(output)
    else:
        return output
```

### 阶段 3: 性能优化
- 使用共享内存减少序列化开销
- 批处理优化
- 异步处理

---

## 具体对接建议

请提供外部系统的详细信息：
1. Tensor 格式：PyTorch / TensorFlow / NumPy？
2. 传递方式：HTTP / gRPC / 共享内存？
3. 数据格式：shape、dtype、normalization？
4. 性能需求：延迟要求、吞吐量？

根据这些信息，我可以设计更具体的对接方案。
