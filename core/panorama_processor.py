"""
å…¨æ™¯å›¾åƒå¤„ç†å™¨æ ¸å¿ƒç±»
åè°ƒæ‰€æœ‰APIæœåŠ¡å®Œæˆå®Œæ•´çš„å¤„ç†æµç¨‹
"""

import os
import sys
import logging
import time
import json
from typing import List, Dict, Any
from PIL import Image

# æ·»åŠ é…ç½®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
config_path = os.path.join(current_dir, '..', 'config')
sys.path.append(config_path)

from utils.api_utils import APIClient

logger = logging.getLogger(__name__)

class PanoramaProcessor:
    """å…¨æ™¯å›¾åƒå¤„ç†å™¨ - åè°ƒæ‰€æœ‰APIæœåŠ¡"""
    
    def __init__(self, output_root_dir: str = "output", api_version: str = "original", output_file: str = "results.json"):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            output_root_dir: è¾“å‡ºæ ¹ç›®å½•
            api_version: APIç‰ˆæœ¬é€‰æ‹©ï¼Œ'original' æˆ– 'shared_left'
            output_file: è¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤ results.jsonï¼‰
        """
        self.output_root_dir = output_root_dir
        self.api_version = api_version
        self.output_file = output_file
        
        # ä½¿ç”¨ç»Ÿä¸€é…ç½®
        from config.api_config import get_api_ports, get_gpu_id, API_BASE_URL
        
        self.API_PORTS = get_api_ports(api_version)
        self.API_BASE_URL = API_BASE_URL
        gpu_id = get_gpu_id(api_version)
        
        logger.info(f"ğŸ”„ ä½¿ç”¨ {api_version} ç‰ˆæœ¬API (ç«¯å£ {self.API_PORTS['preprocess']}-{self.API_PORTS['quality']}, GPU {gpu_id})")
        
        self.api_client = APIClient(API_BASE_URL)
        self.setup_output_dirs()
    
    def setup_output_dirs(self):
        """è®¾ç½®è¾“å‡ºç›®å½• - ä¸å†éœ€è¦å…¨å±€ç›®å½•ï¼Œæ¯ä¸ªç»„æœ‰è‡ªå·±çš„ç›®å½•ç»“æ„"""
        # åªéœ€è¦ç¡®ä¿è¾“å‡ºæ ¹ç›®å½•å­˜åœ¨
        os.makedirs(self.output_root_dir, exist_ok=True)
        logger.info(f"åˆ›å»ºè¾“å‡ºæ ¹ç›®å½•: {self.output_root_dir}")
    
    def super_resolve_pairs(self, pairs_data: List[Dict]) -> List[Dict]:
        """è¶…åˆ†è¾¨ç‡å¤„ç†å›¾åƒå¯¹ - ä¼˜åŒ–ç‰ˆï¼šå…ˆåˆ‡åˆ†å†æ‰¹é‡è¶…åˆ†"""
        logger.info(f"å¼€å§‹è¶…åˆ†è¾¨ç‡å¤„ç† {len(pairs_data)} ä¸ªå›¾åƒå¯¹")
        
        # preprocess APIè¿”å›çš„æ˜¯ä¸€ä¸ªåŒ…å«å¤šä¸ªå›¾åƒå¯¹çš„åˆ—è¡¨ï¼Œéœ€è¦å±•å¼€
        osediff_pairs_data = []
        for panorama_result in pairs_data:
            # æ¯ä¸ªpanorama_resultåŒ…å«å¤šä¸ªå›¾åƒå¯¹
            if isinstance(panorama_result, list):
                # å¦‚æœè¿”å›çš„æ˜¯åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
                for pair_data in panorama_result:
                    if 'pair_image' in pair_data:
                        osediff_pairs_data.append({
                            'pair_image': pair_data['pair_image'],
                            # ä¿ç•™åŸå§‹å‚æ•°ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨
                            'main_params': pair_data.get('main_params', {}),
                            'rand_params': pair_data.get('rand_params', {}),
                            'main_params_file': pair_data.get('main_params_file', ''),
                            'rand_params_file': pair_data.get('rand_params_file', ''),
                            'interval': pair_data.get('interval', 0),
                            'yaw_interval': pair_data.get('yaw_interval', [])
                        })
            elif isinstance(panorama_result, dict) and 'pair_image' in panorama_result:
                # å¦‚æœè¿”å›çš„æ˜¯å•ä¸ªå­—å…¸
                osediff_pairs_data.append({
                    'pair_image': panorama_result['pair_image'],
                    # ä¿ç•™åŸå§‹å‚æ•°ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨
                    'main_params': panorama_result.get('main_params', {}),
                    'rand_params': panorama_result.get('rand_params', {}),
                    'main_params_file': panorama_result.get('main_params_file', ''),
                    'rand_params_file': panorama_result.get('rand_params_file', ''),
                    'interval': panorama_result.get('interval', 0),
                    'yaw_interval': panorama_result.get('yaw_interval', [])
                })
        
        logger.info(f"è½¬æ¢ä¸ºOSEDiffæ ¼å¼: {len(osediff_pairs_data)} ä¸ªå›¾åƒå¯¹")
        
        # ä¼˜åŒ–ï¼šå…ˆåˆ‡åˆ†æ‰€æœ‰å›¾åƒå¯¹æˆå•å›¾ï¼Œç„¶åæ‰¹é‡è¶…åˆ†ï¼Œæœ€åå†æ‹¼æ¥
        try:
            from PIL import Image
            import re
            
            # ç¬¬ä¸€æ­¥ï¼šåˆ‡åˆ†æ‰€æœ‰å›¾åƒå¯¹å¹¶æ”¶é›†å•å›¾
            all_single_images = []  # å­˜å‚¨æ‰€æœ‰å•å›¾çš„ä¿¡æ¯
            for pair_data in osediff_pairs_data:
                pair_image_path = pair_data['pair_image']
                
                if not os.path.exists(pair_image_path):
                    logger.warning(f"å›¾åƒå¯¹ä¸å­˜åœ¨: {pair_image_path}")
                    continue
                
                # è¯»å–å¹¶åˆ‡åˆ†å›¾åƒå¯¹
                pair_img = Image.open(pair_image_path)
                width, height = pair_img.size
                half_width = width // 2
                
                # åˆ‡åˆ†å·¦å³å›¾
                left_img = pair_img.crop((0, 0, half_width, height))
                right_img = pair_img.crop((half_width, 0, width, height))
                
                # ä¿å­˜ä¸´æ—¶åˆ‡åˆ†å›¾åƒ
                base_name = os.path.splitext(os.path.basename(pair_image_path))[0]
                temp_dir = os.path.join(os.path.dirname(pair_image_path), 'temp_split')
                os.makedirs(temp_dir, exist_ok=True)
                
                left_temp_path = os.path.join(temp_dir, f"{base_name}_left_temp.jpg")
                right_temp_path = os.path.join(temp_dir, f"{base_name}_right_temp.jpg")
                
                left_img.save(left_temp_path, quality=95)
                right_img.save(right_temp_path, quality=95)
                
                # è®°å½•å•å›¾ä¿¡æ¯
                all_single_images.append({
                    'input_path': left_temp_path,
                    'type': 'left',
                    'pair_data': pair_data,
                    'original_pair_path': pair_image_path
                })
                all_single_images.append({
                    'input_path': right_temp_path,
                    'type': 'right',
                    'pair_data': pair_data,
                    'original_pair_path': pair_image_path
                })
            
            logger.info(f"åˆ‡åˆ†å®Œæˆï¼Œå…± {len(all_single_images)} å¼ å•å›¾å¾…è¶…åˆ†")
            
            # ç¬¬äºŒæ­¥ï¼šæ‰¹é‡è¶…åˆ†æ‰€æœ‰å•å›¾
            # æå–groupç›®å½•ç”¨äºä¿å­˜è¶…åˆ†ç»“æœ
            if all_single_images:
                first_pair_path = all_single_images[0]['original_pair_path']
                match = re.search(r'/group_\d+/', first_pair_path)
                if match:
                    group_dir_match = match.group(0)
                    group_root_dir = first_pair_path[:first_pair_path.find(group_dir_match) + len(group_dir_match) - 1]
                    group_root_dir = os.path.abspath(group_root_dir)
                    
                    # åˆ›å»ºä¸´æ—¶è¶…åˆ†è¾“å‡ºç›®å½•
                    sr_temp_dir = os.path.join(group_root_dir, 'temp_sr')
                    os.makedirs(sr_temp_dir, exist_ok=True)
                    
                    # æ‰¹é‡è°ƒç”¨è¶…åˆ†API
                    for img_info in all_single_images:
                        response = self.api_client.call_api(
                            port=self.API_PORTS['osediff'],
                            endpoint='super_resolution',
                            data={
                                'input_path': img_info['input_path'],
                                'output_dir': group_root_dir,
                                'align_method': 'adain'
                            }
                        )
                        
                        if response.get('success'):
                            output_path = response.get('output_path')
                            # ç§»åŠ¨åˆ°ä¸´æ—¶ç›®å½•
                            import shutil
                            filename = os.path.basename(output_path)
                            target_path = os.path.join(sr_temp_dir, filename)
                            shutil.move(output_path, target_path)
                            img_info['sr_path'] = target_path
                        else:
                            logger.error(f"å•å›¾è¶…åˆ†å¤±è´¥: {img_info['input_path']}")
                            img_info['sr_path'] = None
                    
                    logger.info(f"æ‰¹é‡è¶…åˆ†å®Œæˆ")
                    
                    # ç¬¬ä¸‰æ­¥ï¼šé‡æ–°æ‹¼æ¥æˆå›¾åƒå¯¹
                    results = []
                    pair_dict = {}  # ç”¨äºæŒ‰åŸå§‹å›¾åƒå¯¹åˆ†ç»„
                    
                    for img_info in all_single_images:
                        pair_path = img_info['original_pair_path']
                        if pair_path not in pair_dict:
                            pair_dict[pair_path] = {'left': None, 'right': None, 'pair_data': img_info['pair_data']}
                        
                        pair_dict[pair_path][img_info['type']] = img_info.get('sr_path')
                    
                    # æ‹¼æ¥å·¦å³å›¾
                    for pair_path, pair_info in pair_dict.items():
                        left_sr = pair_info['left']
                        right_sr = pair_info['right']
                        
                        if left_sr and right_sr and os.path.exists(left_sr) and os.path.exists(right_sr):
                            # è¯»å–è¶…åˆ†åçš„å·¦å³å›¾
                            left_img = Image.open(left_sr)
                            right_img = Image.open(right_sr)
                            
                            # æ‹¼æ¥
                            total_width = left_img.width + right_img.width
                            total_height = max(left_img.height, right_img.height)
                            merged_img = Image.new('RGB', (total_width, total_height))
                            merged_img.paste(left_img, (0, 0))
                            merged_img.paste(right_img, (left_img.width, 0))
                            
                            # ä¿å­˜æ‹¼æ¥åçš„å›¾åƒå¯¹åˆ°osediffç›®å½•
                            base_name = os.path.splitext(os.path.basename(pair_path))[0]
                            osediff_dir = os.path.join(group_root_dir, 'osediff')
                            os.makedirs(osediff_dir, exist_ok=True)
                            output_pair_path = os.path.join(osediff_dir, f"{base_name}.jpg")
                            merged_img.save(output_pair_path, quality=95)
                            
                            # æ„å»ºç»“æœ
                            result_entry = pair_info['pair_data'].copy()
                            result_entry['super_resolved'] = output_pair_path
                            result_entry['align_method'] = 'adain'
                            results.append(result_entry)
                            
                            logger.info(f"å›¾åƒå¯¹è¶…åˆ†å®Œæˆ: {output_pair_path}")
                        else:
                            logger.warning(f"è·³è¿‡ä¸å®Œæ•´çš„å›¾åƒå¯¹: {pair_path}")
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    import shutil
                    temp_dir = os.path.join(os.path.dirname(first_pair_path), 'temp_split')
                    if os.path.exists(temp_dir):
                        shutil.rmtree(temp_dir)
                    if os.path.exists(sr_temp_dir):
                        shutil.rmtree(sr_temp_dir)
                    
                    logger.info(f"è¶…åˆ†è¾¨ç‡å¤„ç†å®Œæˆï¼Œç”Ÿæˆäº† {len(results)} ä¸ªç»“æœ")
                    return results
                else:
                    logger.error("æ— æ³•ä»è·¯å¾„æå–ç»„ç›®å½•")
                    return []
            else:
                logger.warning("æ²¡æœ‰å›¾åƒå¯¹éœ€è¦è¶…åˆ†")
                return []
                
        except Exception as e:
            logger.error(f"è¶…åˆ†è¾¨ç‡å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def evaluate_quality(self, pairs_data: List[Dict]) -> List[Dict]:
        """è¯„ä¼°å›¾åƒå¯¹è´¨é‡"""
        logger.info(f"å¼€å§‹è´¨é‡è¯„ä¼° {len(pairs_data)} ä¸ªå›¾åƒå¯¹")
        
        # è½¬æ¢OSEDiffè¿”å›çš„æ•°æ®æ ¼å¼ä¸ºQuality APIæœŸæœ›çš„æ ¼å¼
        quality_pairs_data = []
        for pair_data in pairs_data:
            if 'super_resolved' in pair_data:
                # OSEDiffè¿”å›çš„æ ¼å¼ï¼Œè½¬æ¢ä¸ºQuality APIæœŸæœ›çš„æ ¼å¼
                quality_pairs_data.append({
                    'pair_image': pair_data['super_resolved'],
                    'original_pair': pair_data.get('original_pair', ''),
                    'align_method': pair_data.get('align_method', 'adain'),
                    # ä¿ç•™åŸå§‹å‚æ•°
                    'main_params': pair_data.get('main_params', {}),
                    'rand_params': pair_data.get('rand_params', {}),
                    'main_params_file': pair_data.get('main_params_file', ''),
                    'rand_params_file': pair_data.get('rand_params_file', ''),
                    'interval': pair_data.get('interval', 0),
                    'yaw_interval': pair_data.get('yaw_interval', [])
                })
            elif 'pair_image' in pair_data:
                # å·²ç»æ˜¯Quality APIæœŸæœ›çš„æ ¼å¼ï¼Œä¿ç•™æ‰€æœ‰åŸå§‹å­—æ®µ
                quality_pairs_data.append(pair_data)
        
        logger.info(f"è½¬æ¢ä¸ºQuality APIæ ¼å¼: {len(quality_pairs_data)} ä¸ªå›¾åƒå¯¹")
        
        try:
            response = self.api_client.call_api(
                port=self.API_PORTS['quality'],
                endpoint='evaluate_pairs',
                data={'pairs_data': quality_pairs_data}
            )
            
            if response.get('success'):
                results = response.get('results', [])
                logger.info(f"è´¨é‡è¯„ä¼°å®Œæˆï¼Œè¯„ä¼°äº† {len(results)} ä¸ªå›¾åƒå¯¹")
                return results
            else:
                logger.error(f"è´¨é‡è¯„ä¼°å¤±è´¥: {response.get('error')}")
                return []
                
        except Exception as e:
            logger.error(f"è´¨é‡è¯„ä¼°APIè°ƒç”¨å¤±è´¥: {e}")
            return []
    
    def generate_panorama2_descriptions(self, filtered_results: List[Dict], panorama2_path: str, group_id: int) -> Dict:
        """ä¸º panorama2 çš„å³å›¾ç”Ÿæˆæ–‡æœ¬æè¿°"""
        logger.info(f"å¼€å§‹ä¸º panorama2 çš„å³å›¾ç”Ÿæˆæè¿°")
        
        from PIL import Image
        import re
        
        # æå– panorama2 çš„æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        panorama2_basename = os.path.splitext(os.path.basename(panorama2_path))[0]
        
        # æ”¶é›† panorama2 çš„å›¾åƒå¯¹å¹¶æå–å³å›¾
        panorama2_right_images = []
        group_root_dir = None
        
        for result in filtered_results:
            pair_image_path = result.get('image_path') or result.get('pair_image')
            if not pair_image_path:
                continue
            
            # åˆ¤æ–­æ˜¯å¦å±äº panorama2
            if panorama2_basename in os.path.basename(pair_image_path):
                try:
                    # è¯»å–å›¾åƒå¯¹
                    pair_img = Image.open(pair_image_path)
                    width, height = pair_img.size
                    half_width = width // 2
                    
                    # æå–å³å›¾
                    right_img = pair_img.crop((half_width, 0, width, height))
                    
                    # ä¿å­˜ä¸´æ—¶å³å›¾
                    base_name = os.path.splitext(os.path.basename(pair_image_path))[0]
                    
                    # æå–ç»„ç›®å½•
                    match = re.search(r'/group_\d+/', pair_image_path)
                    if match:
                        group_dir_match = match.group(0)
                        group_root_dir = pair_image_path[:pair_image_path.find(group_dir_match) + len(group_dir_match) - 1]
                        group_root_dir = os.path.abspath(group_root_dir)
                        
                        # åˆ›å»ºæè¿°ç›®å½•
                        desc_dir = os.path.join(group_root_dir, 'descriptions')
                        os.makedirs(desc_dir, exist_ok=True)
                        
                        # ä¿å­˜å³å›¾
                        right_img_path = os.path.join(desc_dir, f"{base_name}_right.jpg")
                        right_img.save(right_img_path, quality=95)
                        
                        panorama2_right_images.append({
                            'image_path': right_img_path,
                            'original_pair': pair_image_path,
                            'interval': result.get('interval'),
                            'yaw_interval': result.get('yaw_interval')
                        })
                        
                        logger.info(f"æå– panorama2 å³å›¾: {right_img_path}")
                    
                except Exception as e:
                    logger.error(f"æå–å³å›¾å¤±è´¥: {pair_image_path} - {e}")
                    continue
        
        logger.info(f"å…±æå–äº† {len(panorama2_right_images)} å¼  panorama2 çš„å³å›¾")
        
        # æ‰¹é‡ç”Ÿæˆæè¿°
        if panorama2_right_images:
            try:
                # æå–æ‰€æœ‰å›¾åƒè·¯å¾„
                image_paths = [img['image_path'] for img in panorama2_right_images]
                
                # è°ƒç”¨ Quality API ç”Ÿæˆæè¿°
                response = self.api_client.call_api(
                    port=self.API_PORTS['quality'],
                    endpoint='generate_descriptions',
                    data={'image_paths': image_paths}
                )
                
                if response.get('success'):
                    descriptions = response.get('results', [])
                    
                    # å°†æè¿°ä¸å›¾åƒä¿¡æ¯å…³è”
                    for img_info, desc_result in zip(panorama2_right_images, descriptions):
                        img_info['description'] = desc_result.get('description', '')
                        img_info['description_error'] = desc_result.get('error', '')
                    
                    # ä¿å­˜æè¿°åˆ° JSON æ–‡ä»¶
                    if group_root_dir:
                        desc_json_path = os.path.join(group_root_dir, 'descriptions', 'panorama2_right_descriptions.json')
                        with open(desc_json_path, 'w', encoding='utf-8') as f:
                            json.dump(panorama2_right_images, f, indent=2, ensure_ascii=False)
                        logger.info(f"æè¿°å·²ä¿å­˜: {desc_json_path}")
                    
                    logger.info(f"æè¿°ç”Ÿæˆå®Œæˆï¼Œå…± {len(descriptions)} æ¡")
                    return {
                        'success': True,
                        'descriptions': panorama2_right_images,
                        'count': len(panorama2_right_images)
                    }
                else:
                    logger.error(f"æè¿°ç”Ÿæˆå¤±è´¥: {response.get('error')}")
                    return {'success': False, 'error': response.get('error')}
                    
            except Exception as e:
                logger.error(f"æè¿°ç”ŸæˆAPIè°ƒç”¨å¤±è´¥: {e}")
                return {'success': False, 'error': str(e)}
        else:
            logger.warning("æ²¡æœ‰ panorama2 çš„å³å›¾éœ€è¦ç”Ÿæˆæè¿°")
            return {'success': True, 'descriptions': [], 'count': 0}
    
    def process_image_group(self, panorama_path1: str, panorama_path2: str, group_id: int) -> Dict:
        """å¤„ç†å›¾ç‰‡ç»„ï¼ˆä¸¤å¼ å…¨æ™¯å›¾ï¼‰"""
        logger.info(f"å¼€å§‹å¤„ç†å›¾ç‰‡ç»„ #{group_id}: {os.path.basename(panorama_path1)} + {os.path.basename(panorama_path2)}")
        start_time = time.time()
        
        try:
            # 1. é¢„å¤„ç†ä¸¤å¼ å…¨æ™¯å›¾ï¼Œå¹¶ç¡®ä¿å³å›¾å‚æ•°ä¸€è‡´
            preprocess_results1 = self.preprocess_panoramas_for_group(panorama_path1, group_id, is_first=True)
            preprocess_results2 = self.preprocess_panoramas_for_group(panorama_path2, group_id, is_first=False)
            
            if not preprocess_results1 or not preprocess_results2:
                raise Exception("é¢„å¤„ç†å¤±è´¥")
            
            # åˆå¹¶ä¸¤ç»„é¢„å¤„ç†ç»“æœ
            all_preprocess_results = preprocess_results1 + preprocess_results2
            
            # 2. è¶…åˆ†è¾¨ç‡å¤„ç†
            sr_results = self.super_resolve_pairs(all_preprocess_results)
            if not sr_results:
                raise Exception("è¶…åˆ†è¾¨ç‡å¤„ç†å¤±è´¥")
            
            # 3. è´¨é‡è¯„ä¼°
            quality_results = self.evaluate_quality(sr_results)
            if not quality_results:
                raise Exception("è´¨é‡è¯„ä¼°å¤±è´¥")
            
            # 4. è´¨é‡è¿‡æ»¤ï¼ˆæŒ‰ç»„å–æœ€ä½åˆ†ï¼‰
            filtered_results = self.filter_high_quality_results_by_group(quality_results, threshold=0.7)
            if not filtered_results:
                logger.warning(f"å›¾ç‰‡ç»„ #{group_id} æ²¡æœ‰é«˜è´¨é‡å›¾åƒ")
                return {
                    "group_id": group_id,
                    "panorama1": panorama_path1,
                    "panorama2": panorama_path2,
                    "error": "æ²¡æœ‰é«˜è´¨é‡å›¾åƒ",
                    "processing_time": time.time() - start_time,
                    "success": False
                }
            
            # 4.5. ä¸º panorama2 çš„å³å›¾ç”Ÿæˆæè¿°
            desc_result = self.generate_panorama2_descriptions(filtered_results, panorama_path2, group_id)
            if desc_result.get('success'):
                logger.info(f"æˆåŠŸç”Ÿæˆ {desc_result.get('count', 0)} æ¡å›¾åƒæè¿°")
            else:
                logger.warning(f"æè¿°ç”Ÿæˆå¤±è´¥: {desc_result.get('error', 'unknown')}")
            
            # 5. åˆ‡åˆ†å›¾åƒå¯¹å¹¶æ‰§è¡Œå‚æ•°æ’å€¼
            logger.info(f"å¼€å§‹åˆ‡åˆ†å›¾åƒå¯¹å¹¶æ‰§è¡Œå‚æ•°æ’å€¼ï¼Œä¼ å…¥ {len(filtered_results)} ä¸ªå›¾åƒå¯¹")
            if filtered_results:
                logger.info(f"ç¬¬ä¸€ä¸ªå›¾åƒå¯¹çš„æ•°æ®ç¤ºä¾‹: {filtered_results[0]}")
            
            # åˆ‡åˆ†å›¾åƒå¯¹ä¸ºå·¦å³å›¾
            split_results = self.split_pairs_for_interpolation(filtered_results, group_id)
            if not split_results:
                raise Exception("åˆ‡åˆ†å›¾åƒå¯¹å¤±è´¥")
            
            # æ‰§è¡Œå‚æ•°æ’å€¼ç”Ÿæˆæ–°å›¾åƒ
            interpolated_results = self.generate_interpolated_images(
                split_results, panorama_path1, panorama_path2, group_id
            )
            if not interpolated_results:
                raise Exception("å‚æ•°æ’å€¼ç”Ÿæˆå›¾åƒå¤±è´¥")
            
            # å¯¹æ’å€¼åçš„å›¾åƒè¿›è¡Œè¶…åˆ†å¤„ç†
            interpolated_sr_results = self.super_resolve_interpolated_pairs(interpolated_results)
            if not interpolated_sr_results:
                raise Exception("æ’å€¼å›¾åƒè¶…åˆ†å¤„ç†å¤±è´¥")
            
            # 6. åˆ›å»ºæœ€ç»ˆæ•°æ®ï¼ˆæŒ‰yawåŒºé—´ç»„ç»‡ï¼‰
            final_data = self.create_final_data_with_interpolation(
                split_results,
                interpolated_sr_results,
                sr_results,
                group_id,
                panorama_path1,
                panorama_path2,
                desc_result  # ä¼ å…¥æè¿°ä¿¡æ¯
            )
            
            processing_time = time.time() - start_time
            
            result = {
                "group_id": group_id,
                "panorama1": panorama_path1,
                "panorama2": panorama_path2,
                "preprocess_results": all_preprocess_results,
                "super_resolution_results": sr_results,
                "quality_results": quality_results,
                "filtered_results": filtered_results,
                "descriptions": desc_result,  # æ·»åŠ æè¿°ä¿¡æ¯
                "split_results": split_results,
                "interpolated_results": interpolated_results,
                "interpolated_sr_results": interpolated_sr_results,
                "final_data": final_data,
                "processing_time": processing_time,
                "success": True
            }
            
            logger.info(f"å›¾ç‰‡ç»„ #{group_id} å¤„ç†å®Œæˆ (è€—æ—¶: {processing_time:.2f}ç§’)")
            return result
            
        except Exception as e:
            logger.error(f"å¤„ç†å›¾ç‰‡ç»„ #{group_id} å¤±è´¥: {e}")
            return {
                "group_id": group_id,
                "panorama1": panorama_path1,
                "panorama2": panorama_path2,
                "error": str(e),
                "processing_time": time.time() - start_time,
                "success": False
            }
    
    def preprocess_panoramas_for_group(self, panorama_path: str, group_id: int, is_first: bool) -> List[Dict]:
        """ä¸ºå›¾ç‰‡ç»„é¢„å¤„ç†å•å¼ å…¨æ™¯å›¾"""
        logger.info(f"é¢„å¤„ç† {'ç¬¬ä¸€å¼ ' if is_first else 'ç¬¬äºŒå¼ '}å…¨æ™¯å›¾: {os.path.basename(panorama_path)}")
        
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(panorama_path):
            panorama_path = os.path.abspath(panorama_path)
        
        try:
            # è°ƒç”¨é¢„å¤„ç†APIï¼Œä¼ å…¥ç»„IDä¿¡æ¯
            response = self.api_client.call_api(
                port=self.API_PORTS['preprocess'],
                endpoint='preprocess_for_group',
                data={
                    'image_path': panorama_path,
                    'group_id': group_id,
                    'is_first': is_first
                }
            )
            
            if response.get('success'):
                results = response.get('results', [])
                logger.info(f"é¢„å¤„ç†å®Œæˆï¼Œç”Ÿæˆäº† {len(results)} ä¸ªç»“æœ")
                return results
            else:
                logger.error(f"é¢„å¤„ç†å¤±è´¥: {response.get('error')}")
                return []
                
        except Exception as e:
            logger.error(f"é¢„å¤„ç†APIè°ƒç”¨å¤±è´¥: {e}")
            return []
    
    def filter_high_quality_results_by_group(self, quality_results: List[Dict], threshold: float = 0.7) -> List[Dict]:
        """æŒ‰ç»„è¿‡æ»¤é«˜è´¨é‡ç»“æœï¼ˆåœ¨åŒä¸€yawåŒºé—´å†…å–æœ€ä½åˆ†ï¼‰"""
        # å…ˆæŒ‰intervalåˆ†ç»„
        interval_dict = {}
        for result in quality_results:
            interval = result.get('interval', 0)
            if interval not in interval_dict:
                interval_dict[interval] = []
            interval_dict[interval].append(result)
        
        # å¯¹æ¯ä¸ªintervalå†…çš„pairå–æœ€ä½åˆ†
        filtered_results = []
        for interval, results in interval_dict.items():
            # æå–æ‰€æœ‰åˆ†æ•°å¹¶è½¬æ¢ä¸ºfloat
            scores = []
            for r in results:
                score = r.get('final_score')
                if score is not None:
                    try:
                        scores.append(float(score))
                    except (ValueError, TypeError):
                        logger.warning(f"æ— æ³•è½¬æ¢åˆ†æ•°ä¸ºfloat: {score}")
            
            if scores:
                min_score = min(scores)
                
                if min_score >= threshold:
                    logger.info(f"yawåŒºé—´ {interval} é€šè¿‡è´¨é‡ç­›é€‰ (æœ€ä½åˆ†: {min_score:.3f})")
                    filtered_results.extend(results)
                else:
                    logger.info(f"yawåŒºé—´ {interval} æœªé€šè¿‡è´¨é‡ç­›é€‰ (æœ€ä½åˆ†: {min_score:.3f})")
            else:
                logger.warning(f"yawåŒºé—´ {interval} æ²¡æœ‰æœ‰æ•ˆçš„åˆ†æ•°ï¼Œè·³è¿‡")
        
        logger.info(f"è´¨é‡è¿‡æ»¤å®Œæˆï¼Œä» {len(quality_results)} ä¸ªç»“æœä¸­ä¿ç•™äº† {len(filtered_results)} ä¸ª")
        return filtered_results
    
    def save_single_group_result(self, result: Dict):
        """ä¿å­˜å•ä¸ªå›¾ç‰‡ç»„çš„å¤„ç†ç»“æœï¼ˆå®æ—¶ä¿å­˜ï¼‰"""
        try:
            # æ„å»ºå®Œæ•´çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
            output_file_path = os.path.join(self.output_root_dir, self.output_file)
            
            # è¯»å–ç°æœ‰çš„results
            existing_results = []
            if os.path.exists(output_file_path):
                with open(output_file_path, 'r', encoding='utf-8') as f:
                    existing_results = json.load(f)
            
            # æ·»åŠ æœ¬æ¬¡çš„ç»“æœï¼ˆå¦‚æœæ˜¯æˆåŠŸçš„è¯ï¼‰
            if result.get('success', False) and 'final_data' in result:
                new_entries = result.get('final_data', [])
                existing_results.extend(new_entries)
                
                # ä¿å­˜æ›´æ–°çš„results.json
                with open(output_file_path, 'w', encoding='utf-8') as f:
                    json.dump(existing_results, f, ensure_ascii=False, indent=2)
                
                logger.info(f"å®æ—¶æ›´æ–° {self.output_file}ï¼Œå½“å‰å…±æœ‰ {len(existing_results)} ä¸ªæ•°æ®æ¡ç›®")
            
            # ç”Ÿæˆæˆ–æ›´æ–° group_info.jsonï¼ˆæ— è®ºæˆåŠŸå¤±è´¥éƒ½ç”Ÿæˆï¼‰
            group_id = result.get('group_id')
            panorama1 = result.get('panorama1', '')
            panorama2 = result.get('panorama2', '')
            processing_time = result.get('processing_time', 0)
            success = result.get('success', False)
            
            # ç¡®å®šgroupç›®å½•ä½ç½®
            group_dir_name = f"group_{group_id:04d}"
            if 'preprocess' in self.output_root_dir:
                parent_dir = os.path.dirname(self.output_root_dir)
                group_dir = os.path.join(parent_dir, group_dir_name)
            else:
                group_dir = os.path.join(self.output_root_dir, group_dir_name)
            
            # æ„å»ºgroup_info
            if success and 'final_data' in result:
                final_data = result.get('final_data', [])
                yaw_intervals = []
                for entry in final_data:
                    interval_info = entry.get('yaw_interval', {})
                    yaw_intervals.append({
                        'interval_id': interval_info.get('interval_id'),
                        'yaw_min': interval_info.get('yaw_min'),
                        'yaw_max': interval_info.get('yaw_max')
                    })
                
                group_info = {
                    'group_id': group_id,
                    'panorama1': os.path.basename(panorama1),
                    'panorama2': os.path.basename(panorama2),
                    'panorama1_path': panorama1,
                    'panorama2_path': panorama2,
                    'num_quadruples': len(final_data),
                    'yaw_intervals': yaw_intervals,
                    'processing_time': processing_time,
                    'success': True
                }
            else:
                # å¤±è´¥æˆ–æ²¡æœ‰é«˜è´¨é‡æ•°æ®çš„æƒ…å†µ
                error_msg = result.get('error', 'æ— æ•°æ®æˆ–å¤„ç†å¤±è´¥')
                group_info = {
                    'group_id': group_id,
                    'panorama1': os.path.basename(panorama1) if panorama1 else '',
                    'panorama2': os.path.basename(panorama2) if panorama2 else '',
                    'panorama1_path': panorama1 if panorama1 else '',
                    'panorama2_path': panorama2 if panorama2 else '',
                    'num_quadruples': 0,
                    'yaw_intervals': [],
                    'processing_time': processing_time,
                    'success': False,
                    'error': error_msg
                }
            
            # ä¿å­˜ group_info.json
            group_info_file = os.path.join(group_dir, 'group_info.json')
            with open(group_info_file, 'w', encoding='utf-8') as f:
                json.dump(group_info, f, ensure_ascii=False, indent=2)
            logger.info(f"ç»„ä¿¡æ¯å·²å®æ—¶ä¿å­˜: {group_info_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜å•ä¸ªç»„ç»“æœå¤±è´¥: {e}")
    
    def count_current_intervals(self) -> int:
        """ç»Ÿè®¡å½“å‰ results.json ä¸­çš„ yaw_interval æ•°é‡"""
        output_file_path = os.path.join(self.output_root_dir, self.output_file)
        
        if not os.path.exists(output_file_path):
            return 0
        
        try:
            with open(output_file_path, 'r', encoding='utf-8') as f:
                results = json.load(f)
            
            # results.json æ˜¯æ‰å¹³åŒ–çš„ yaw_interval åˆ—è¡¨
            # æ¯ä¸ªæ¡ç›®å°±æ˜¯ä¸€ä¸ª yaw_intervalï¼Œç›´æ¥è¿”å›åˆ—è¡¨é•¿åº¦
            if isinstance(results, list):
                return len(results)
            else:
                return 0
        except Exception as e:
            logger.warning(f"ç»Ÿè®¡ yaw_interval æ•°é‡æ—¶å‡ºé”™: {e}")
            return 0
    
    def split_pairs_for_interpolation(self, filtered_results: List[Dict], group_id: int) -> List[Dict]:
        """åˆ‡åˆ†å›¾åƒå¯¹ä¸ºå·¦å³ä¸¤éƒ¨åˆ†ï¼ˆç”¨äºæ’å€¼ï¼‰"""
        logger.info(f"å¼€å§‹åˆ‡åˆ† {len(filtered_results)} ä¸ªå›¾åƒå¯¹")
        
        # æå–ç»„ç›®å½•
        split_results = []
        for result in filtered_results:
            try:
                pair_image_path = result.get('pair_image', '')
                if not pair_image_path or not os.path.exists(pair_image_path):
                    logger.warning(f"å›¾åƒå¯¹ä¸å­˜åœ¨: {pair_image_path}")
                    continue
                
                # ä»è·¯å¾„ä¸­æå–ç»„ç›®å½•
                import re
                match = re.search(r'/group_\d+/', pair_image_path)
                if not match:
                    logger.error(f"æ— æ³•ä»è·¯å¾„ä¸­æå–ç»„ç›®å½•: {pair_image_path}")
                    continue
                
                # æå–åŒ¹é…åˆ°çš„ç›®å½•è·¯å¾„ (å¦‚ /group_0001/)
                group_dir_match = match.group(0)
                # æ‰¾åˆ°è¿™ä¸ªç›®å½•ä¹‹å‰çš„éƒ¨åˆ†
                group_root_dir = pair_image_path[:pair_image_path.find(group_dir_match) + len(group_dir_match) - 1]
                group_root_dir = os.path.abspath(group_root_dir)
                
                # åˆ›å»ºinterpolatedç›®å½•ç”¨äºå­˜æ”¾æ’å€¼ç»“æœ
                interpolated_dir = os.path.join(group_root_dir, "interpolated")
                os.makedirs(interpolated_dir, exist_ok=True)
                
                # åˆ‡åˆ†å›¾åƒå¯¹
                img = Image.open(pair_image_path)
                width = img.width
                mid = width // 2
                left_img = img.crop((0, 0, mid, img.height))
                right_img = img.crop((mid, 0, width, img.height))
                
                # ä¿å­˜åˆ‡åˆ†åçš„å›¾åƒ
                base_name = os.path.splitext(os.path.basename(pair_image_path))[0]
                left_path = os.path.join(interpolated_dir, f"{base_name}_left.jpg")
                right_path = os.path.join(interpolated_dir, f"{base_name}_right.jpg")
                left_img.save(left_path)
                right_img.save(right_path)
                
                split_results.append({
                    'pair_image': pair_image_path,
                    'left_image': left_path,
                    'right_image': right_path,
                    'main_params': result.get('main_params'),
                    'rand_params': result.get('rand_params'),
                    'interval': result.get('interval'),
                    'yaw_interval': result.get('yaw_interval'),
                    'group_id': group_id
                })
                
            except Exception as e:
                logger.error(f"åˆ‡åˆ†å›¾åƒå¯¹å¤±è´¥: {e}")
                continue
        
        logger.info(f"åˆ‡åˆ†å®Œæˆï¼Œç”Ÿæˆäº† {len(split_results)} ä¸ªç»“æœ")
        return split_results
    
    def generate_interpolated_images(self, split_results: List[Dict], panorama1_path: str, panorama2_path: str, group_id: int) -> List[Dict]:
        """ä½¿ç”¨æ’å€¼å‚æ•°ä»å…¨æ™¯å›¾ç”Ÿæˆæ–°å›¾åƒ - è°ƒç”¨Preprocess API"""
        logger.info(f"å¼€å§‹ç”Ÿæˆæ’å€¼å›¾åƒï¼Œå…±æœ‰ {len(split_results)} ç»„æ•°æ®")
        
        try:
            response = self.api_client.call_api(
                port=self.API_PORTS['preprocess'],
                endpoint='generate_interpolated_images',
                data={
                    'split_results': split_results,
                    'panorama1_path': panorama1_path,
                    'panorama2_path': panorama2_path,
                    'group_id': group_id
                }
            )
            
            if response.get('success'):
                results = response.get('results', [])
                logger.info(f"æ’å€¼å›¾åƒç”Ÿæˆå®Œæˆï¼Œç”Ÿæˆäº† {len(results)} ä¸ªç»“æœ")
                return results
            else:
                logger.error(f"æ’å€¼å›¾åƒç”Ÿæˆå¤±è´¥: {response.get('error')}")
                return []
                
        except Exception as e:
            logger.error(f"æ’å€¼å›¾åƒç”ŸæˆAPIè°ƒç”¨å¤±è´¥: {e}")
            return []
    
    def super_resolve_interpolated_pairs(self, interpolated_results: List[Dict]) -> List[Dict]:
        """å¯¹æ’å€¼åçš„å›¾åƒè¿›è¡Œè¶…åˆ†å¤„ç†"""
        logger.info(f"å¼€å§‹å¯¹æ’å€¼å›¾åƒè¿›è¡Œè¶…åˆ†å¤„ç†ï¼Œå…± {len(interpolated_results)} ç»„")
        
        # å…ˆè·å–ç¬¬ä¸€ä¸ªæ’å€¼å›¾åƒçš„groupç›®å½•
        if not interpolated_results:
            logger.warning("æ²¡æœ‰æ’å€¼å›¾åƒéœ€è¦è¶…åˆ†")
            return interpolated_results
        
        # ä»ç¬¬ä¸€ä¸ªç»“æœæå–groupä¿¡æ¯
        first_interp = interpolated_results[0].get('interpolated_images', [])
        if not first_interp:
            logger.warning("æ’å€¼å›¾åƒåˆ—è¡¨ä¸ºç©º")
            return interpolated_results
        
        first_path = first_interp[0].get('path', '')
        import re
        match = re.search(r'/group_\d+/', first_path)
        if not match:
            logger.error("æ— æ³•ä»è·¯å¾„æå–ç»„ç›®å½•")
            return interpolated_results
        
        # æå–åŒ¹é…åˆ°çš„ç›®å½•è·¯å¾„ (å¦‚ /group_0001/)
        group_dir_match = match.group(0)
        # æ‰¾åˆ°è¿™ä¸ªç›®å½•ä¹‹å‰çš„éƒ¨åˆ†
        group_root_dir = first_path[:first_path.find(group_dir_match) + len(group_dir_match) - 1]
        group_root_dir = os.path.abspath(group_root_dir)
        
        # åˆ›å»ºè¶…åˆ†è¾“å‡ºç›®å½•
        sr_output_dir = os.path.join(group_root_dir, "interpolated_sr")
        os.makedirs(sr_output_dir, exist_ok=True)
        
        # æ”¶é›†æ‰€æœ‰æ’å€¼å›¾åƒè·¯å¾„
        all_interp_images = []
        
        for interp_group in interpolated_results:
            interp_images = interp_group.get('interpolated_images', [])
            for interp_img in interp_images:
                try:
                    input_path = interp_img.get('path')
                    if not input_path or not os.path.exists(input_path):
                        logger.warning(f"æ’å€¼å›¾åƒä¸å­˜åœ¨: {input_path}")
                        continue
                    
                    all_interp_images.append((interp_img, input_path))
                    
                except Exception as e:
                    logger.error(f"æ”¶é›†æ’å€¼å›¾åƒå¤±è´¥: {interp_img.get('path', 'unknown')} - {e}")
                    continue
        
        logger.info(f"å…±æ”¶é›†äº† {len(all_interp_images)} å¼ æ’å€¼å›¾åƒï¼Œå¼€å§‹æ‰¹é‡è¶…åˆ†å¤„ç†")
        
        # æ‰¹é‡è°ƒç”¨å•å¼ å›¾åƒè¶…åˆ†API
        if all_interp_images:
            try:
                # ä¸ºæ¯ä¸ªå›¾åƒè°ƒç”¨å•å¼ è¶…åˆ†æ¥å£
                for interp_img, input_path in all_interp_images:
                    response = self.api_client.call_api(
                        port=self.API_PORTS['osediff'],
                        endpoint='super_resolution',
                        data={
                            'input_path': input_path,
                            'output_dir': group_root_dir,
                            'align_method': 'adain'
                        }
                    )
                    
                    if response.get('success'):
                        output_path = response.get('output_path')
                        # å°†è¾“å‡ºæ–‡ä»¶ç§»åŠ¨åˆ°interpolated_srç›®å½•
                        import shutil
                        filename = os.path.basename(output_path)
                        target_path = os.path.join(sr_output_dir, filename)
                        shutil.move(output_path, target_path)
                        interp_img['super_resolved'] = target_path
                        logger.info(f"æ’å€¼å›¾åƒè¶…åˆ†æˆåŠŸ: {target_path}")
                    else:
                        logger.error(f"æ’å€¼å›¾åƒè¶…åˆ†å¤±è´¥: {response.get('error')}")
                        
            except Exception as e:
                logger.error(f"æ‰¹é‡è¶…åˆ†å¤„ç†å¤±è´¥: {e}")
        
        logger.info(f"æ’å€¼å›¾åƒè¶…åˆ†å¤„ç†å®Œæˆ")
        return interpolated_results
    
    def create_final_data_with_interpolation(self, split_results: List[Dict], interpolated_sr_results: List[Dict], 
                                            sr_results: List[Dict], group_id: int, panorama1_path: str, panorama2_path: str, 
                                            desc_result: Dict = None) -> List[Dict]:
        """åˆ›å»ºåŒ…å«æ’å€¼å›¾åƒçš„æœ€ç»ˆæ•°æ®"""
        logger.info(f"åˆ›å»ºåŒ…å«æ’å€¼çš„æœ€ç»ˆæ•°æ®")
        
        # æ„å»ºæè¿°å­—å…¸ï¼Œæ–¹ä¾¿æŒ‰ interval æŸ¥æ‰¾
        descriptions_by_interval = {}
        if desc_result and desc_result.get('success') and desc_result.get('descriptions'):
            for desc in desc_result.get('descriptions', []):
                interval = desc.get('interval')
                if interval:
                    descriptions_by_interval[interval] = desc.get('description', '')
        
        final_data = []
        
        # æŒ‰intervalç»„ç»‡æ•°æ®
        interval_to_panoramas = {}  # {interval: {'panorama1': {...}, 'panorama2': {...}}}
        
        for split_result in split_results:
            interval = split_result.get('interval')
            if interval not in interval_to_panoramas:
                interval_to_panoramas[interval] = {}
            
            # åˆ¤æ–­æ˜¯panorama1è¿˜æ˜¯panorama2
            pair_image = split_result.get('pair_image', '')
            pair_basename = os.path.splitext(os.path.basename(pair_image))[0]
            panorama1_basename = os.path.splitext(os.path.basename(panorama1_path))[0]
            panorama2_basename = os.path.splitext(os.path.basename(panorama2_path))[0]
            
            if pair_basename.startswith(panorama1_basename):
                interval_to_panoramas[interval]['panorama1'] = split_result
            elif pair_basename.startswith(panorama2_basename):
                interval_to_panoramas[interval]['panorama2'] = split_result
            else:
                # å¦‚æœæ— æ³•åˆ¤æ–­ï¼Œå°è¯•ä»pair_imageè·¯å¾„åˆ¤æ–­
                if panorama1_basename in pair_image:
                    interval_to_panoramas[interval]['panorama1'] = split_result
                else:
                    interval_to_panoramas[interval]['panorama2'] = split_result
        
        # ä¸ºæ¯ä¸ªintervalåˆ›å»ºæœ€ç»ˆæ•°æ®æ¡ç›®
        for interval, panoramas in sorted(interval_to_panoramas.items()):
            if 'panorama1' not in panoramas or 'panorama2' not in panoramas:
                logger.warning(f"Interval {interval} ç¼ºå°‘å®Œæ•´çš„panoramaæ•°æ®ï¼Œè·³è¿‡")
                continue
            
            p1_split = panoramas['panorama1']
            p2_split = panoramas['panorama2']
            
            # ç»„ç»‡æ’å€¼å›¾åƒæ•°æ®å’Œå‚æ•°
            p1_interp_data = []
            p2_interp_data = []
            p1_params_sequence = []
            p2_params_sequence = []
            
            for interp_group in interpolated_sr_results:
                panorama = interp_group.get('panorama')
                interp_images = interp_group.get('interpolated_images', [])
                
                if panorama == 'panorama1' and interp_group.get('interval') == interval:
                    # æŒ‰ç…§ä»å·¦åˆ°å³çš„é¡ºåºç»„ç»‡ï¼šA1 (left) -> interp_01 -> ... -> interp_09 -> A2 (right)
                    images = [p1_split.get('left_image')]  # èµ·å§‹å·¦å›¾
                    params = [p1_split.get('main_params')]  # èµ·å§‹å·¦å›¾å‚æ•°
                    
                    for interp_img in sorted(interp_images, key=lambda x: x.get('weight_idx', 0)):
                        images.append(interp_img.get('super_resolved', interp_img.get('path')))
                        params.append(interp_img.get('params'))  # æ·»åŠ æ’å€¼å‚æ•°
                    
                    images.append(p1_split.get('right_image'))  # ç»“æŸå³å›¾
                    params.append(p1_split.get('rand_params'))  # ç»“æŸå³å›¾å‚æ•°
                    
                    p1_interp_data = images
                    p1_params_sequence = params
                    
                elif panorama == 'panorama2' and interp_group.get('interval') == interval:
                    images = [p2_split.get('left_image')]
                    params = [p2_split.get('main_params')]
                    
                    for interp_img in sorted(interp_images, key=lambda x: x.get('weight_idx', 0)):
                        images.append(interp_img.get('super_resolved', interp_img.get('path')))
                        params.append(interp_img.get('params'))
                    
                    images.append(p2_split.get('right_image'))
                    params.append(p2_split.get('rand_params'))
                    
                    p2_interp_data = images
                    p2_params_sequence = params
            
            # åˆ›å»ºæœ€ç»ˆæ•°æ®æ¡ç›®
            final_entry = {
                'group_id': group_id,
                'yaw_interval': {
                    'interval_id': interval,
                    'yaw_min': p1_split.get('yaw_interval', (0, 0))[0],
                    'yaw_max': p1_split.get('yaw_interval', (0, 0))[1]
                },
                'panorama1': {
                    'original_path': panorama1_path,
                    'interpolated_sequence': p1_interp_data,  # 11å¼ å›¾ç‰‡åºåˆ—
                    'params_sequence': p1_params_sequence     # 11ç»„å‚æ•°åºåˆ—
                },
                'panorama2': {
                    'original_path': panorama2_path,
                    'interpolated_sequence': p2_interp_data,  # 11å¼ å›¾ç‰‡åºåˆ—
                    'params_sequence': p2_params_sequence,    # 11ç»„å‚æ•°åºåˆ—
                    'right_image_description': descriptions_by_interval.get(interval, '')  # æ·»åŠ å³å›¾æè¿°
                }
            }
            
            final_data.append(final_entry)
            logger.info(f"åˆ›å»ºinterval {interval} çš„æœ€ç»ˆæ•°æ®æ¡ç›®ï¼ŒåŒ…å« {len(p1_interp_data)} + {len(p2_interp_data)} å¼ å›¾åƒ")
        
        logger.info(f"æœ€ç»ˆæ•°æ®åˆ›å»ºå®Œæˆï¼Œå…± {len(final_data)} ä¸ªæ¡ç›®")
        return final_data 